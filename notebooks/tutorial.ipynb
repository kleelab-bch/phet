{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtype Detection using PHet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from src.model.phet import PHeT\n",
    "from src.utility.file_path import DATASET_PATH, RESULT_PATH\n",
    "from src.utility.plot_utils import plot_umap, plot_barplot\n",
    "from src.utility.utils import comparative_score\n",
    "from src.utility.utils import sort_features, significant_features\n",
    "\n",
    "sns.set_theme(style=\"white\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Hyperparamters\n",
    "\n",
    "Two files will be downloaed ontologies and associations. Mapping Genes IDs to namedtuples consist of symbols and other metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "pvalue = 0.01\n",
    "sort_by_pvalue = True\n",
    "topKfeatures = 100\n",
    "plot_topKfeatures = False\n",
    "if not sort_by_pvalue:\n",
    "    plot_topKfeatures = True\n",
    "is_filter = True\n",
    "num_neighbors = 5\n",
    "max_clusters = 10\n",
    "feature_metric = \"f1\"\n",
    "cluster_type = \"spectral\"\n",
    "export_spring = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # descriptions of the data\n",
    "    file_name = \"baron_1\"\n",
    "    suptitle_name = \"Baron\"\n",
    "    control_name = \"0\"\n",
    "    case_name = \"1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Exprssion, classes, subtypes, donors, timepoints Files\n",
    "    expression_file_name = file_name + \"_matrix.mtx\"\n",
    "    features_file_name = file_name + \"_feature_names.csv\"\n",
    "    markers_file = file_name + \"_markers.csv\"\n",
    "    classes_file_name = file_name + \"_classes.csv\"\n",
    "    subtypes_file = file_name + \"_types.csv\"\n",
    "    differential_features_file = file_name + \"_limma_features.csv\"\n",
    "    donors_file = file_name + \"_donors.csv\"\n",
    "    timepoints_file = file_name + \"_timepoints.csv\"\n",
    "\n",
    "    # Load subtypes file\n",
    "    subtypes = pd.read_csv(os.path.join(DATASET_PATH, subtypes_file), sep=',').dropna(axis=1)\n",
    "    subtypes = [str(item[0]).lower() for item in subtypes.values.tolist()]\n",
    "    num_clusters = len(np.unique(subtypes))\n",
    "    donors = []\n",
    "    if os.path.exists(os.path.join(DATASET_PATH, donors_file)):\n",
    "        donors = pd.read_csv(os.path.join(DATASET_PATH, donors_file), sep=',').dropna(axis=1)\n",
    "        donors = [str(item[0]).lower() for item in donors.values.tolist()]\n",
    "    timepoints = []\n",
    "    if os.path.exists(os.path.join(DATASET_PATH, timepoints_file)):\n",
    "        timepoints = pd.read_csv(os.path.join(DATASET_PATH, timepoints_file), sep=',').dropna(axis=1)\n",
    "        timepoints = [str(item[0]).lower() for item in timepoints.values.tolist()]\n",
    "\n",
    "    # Load features, expression, and class data\n",
    "    features_name = pd.read_csv(os.path.join(DATASET_PATH, features_file_name), sep=',')\n",
    "    features_name = features_name[\"features\"].to_list()\n",
    "    y = pd.read_csv(os.path.join(DATASET_PATH, classes_file_name), sep=',')\n",
    "    y = y[\"classes\"].to_numpy()\n",
    "    X = sc.read_mtx(os.path.join(DATASET_PATH, expression_file_name))\n",
    "    X = X.to_df().to_numpy()\n",
    "    np.nan_to_num(X, copy=False, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # Filter data \n",
    "    num_examples, num_features = X.shape\n",
    "    if is_filter:\n",
    "        example_sums = np.absolute(X).sum(1)\n",
    "        examples_ids = np.where(example_sums > int(0.01 * num_features))[0]\n",
    "        X = X[examples_ids]\n",
    "        y = y[examples_ids]\n",
    "        subtypes = np.array(subtypes)[examples_ids].tolist()\n",
    "        if len(donors) != 0:\n",
    "            donors = np.array(donors)[examples_ids].tolist()\n",
    "        if len(timepoints) != 0:\n",
    "            timepoints = np.array(timepoints)[examples_ids].tolist()\n",
    "        num_examples, num_features = X.shape\n",
    "        del example_sums, examples_ids\n",
    "        temp = np.absolute(X)\n",
    "        temp = (temp * 1e6) / temp.sum(axis=1).reshape((num_examples, 1))\n",
    "        temp[temp > 1] = 1\n",
    "        temp[temp != 1] = 0\n",
    "        feature_sums = temp.sum(0)\n",
    "        del temp\n",
    "        feature_ids = np.where(feature_sums > int(0.01 * num_examples))[0]\n",
    "        features_name = np.array(features_name)[feature_ids].tolist()\n",
    "        X = X[:, feature_ids]\n",
    "        num_examples, num_features = X.shape\n",
    "        del feature_sums\n",
    "\n",
    "    # Save subtypes for SPRING\n",
    "    if export_spring:\n",
    "        groups = []\n",
    "        groups.append([\"subtypes\"] + subtypes)\n",
    "        if len(donors) != 0:\n",
    "            groups.append([\"donors\"] + donors)\n",
    "        if len(timepoints) != 0:\n",
    "            groups.append([\"timepoints\"] + timepoints)\n",
    "        df = pd.DataFrame(groups)\n",
    "        df.to_csv(os.path.join(RESULT_PATH, file_name + \"_groups.csv\"), sep=',',\n",
    "                  index=False, header=False)\n",
    "        del df\n",
    "\n",
    "    # Load up/down regulated features\n",
    "    top_features_true = -1\n",
    "    if os.path.exists(os.path.join(DATASET_PATH, markers_file)):\n",
    "        top_features_true = pd.read_csv(os.path.join(DATASET_PATH, markers_file)).replace(np.nan, -1)\n",
    "        top_features_true = list(set([item for item in top_features_true.to_numpy().flatten() if item != -1]))\n",
    "        top_features_true = [1 if feature in top_features_true else 0 for idx, feature in enumerate(features_name)]\n",
    "        topKfeatures = sum(top_features_true)\n",
    "    elif os.path.exists(os.path.join(DATASET_PATH, differential_features_file)):\n",
    "        top_features_true = pd.read_csv(os.path.join(DATASET_PATH, differential_features_file), sep=',',\n",
    "                                        index_col=\"ID\")\n",
    "        temp = [feature for feature in top_features_true.index.to_list() if str(feature) in features_name]\n",
    "        if top_features_true.shape[1] > 0:\n",
    "            top_features_true = top_features_true.loc[temp]\n",
    "            temp = top_features_true[top_features_true[\"adj.P.Val\"] <= pvalue]\n",
    "            if temp.shape[0] < topKfeatures:\n",
    "                temp = top_features_true[:topKfeatures - 1]\n",
    "                if sort_by_pvalue and temp.shape[0] == 0:\n",
    "                    plot_topKfeatures = True\n",
    "            top_features_true = [str(feature_idx) for feature_idx in temp.index.to_list()[:topKfeatures]]\n",
    "        else:\n",
    "            top_features_true = temp\n",
    "            topKfeatures = len(top_features_true)\n",
    "        top_features_true = [1 if feature in top_features_true else 0 for idx, feature in enumerate(features_name)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    print(\"## Perform experimental studies using {0} data...\".format(file_name))\n",
    "    print(\"\\t >> Sample size: {0}; Feature size: {1}; Subtype size: {2}\".format(X.shape[0], X.shape[1],\n",
    "                                                                                len(np.unique(subtypes))))\n",
    "    current_progress = 1\n",
    "    total_progress = len(methods)\n",
    "    methods_dict = dict()\n",
    "\n",
    "    print(\"\\t >> Progress: {0:.4f}%; Method: {1:20}\".format((current_progress / total_progress) * 100,\n",
    "                                                            methods[0]))\n",
    "    estimator = PHeT(normalize=\"zscore\", iqr_range=(25, 75), num_subsamples=1000, calculate_deltaiqr=True,\n",
    "                     calculate_deltahvf=False, calculate_fisher=True, calculate_profile=True, bin_KS_pvalues=False,\n",
    "                     feature_weight=[0.4, 0.3, 0.2, 0.1], weight_range=[0.2, 0.4, 0.8])\n",
    "    df = estimator.fit_predict(X=X, y=y, control_class=0, case_class=1)\n",
    "    methods_dict.update({methods[0]: df})\n",
    "    current_progress += 1\n",
    "\n",
    "    if sort_by_pvalue:\n",
    "        print(\"## Sort features by the cut-off {0:.2f} p-value...\".format(pvalue))\n",
    "    else:\n",
    "        print(\"## Sort features by the score statistic...\".format())\n",
    "    for method_idx, item in enumerate(methods_dict.items()):\n",
    "        method_name, df = item\n",
    "        method_name = methods[method_idx]\n",
    "        save_name = methods_save_name[method_idx]\n",
    "        if sort_by_pvalue:\n",
    "            temp = significant_features(X=df, features_name=features_name, pvalue=pvalue,\n",
    "                                        X_map=None, map_genes=False, ttest=False)\n",
    "        else:\n",
    "            temp = sort_features(X=df, features_name=features_name, X_map=None,\n",
    "                                 map_genes=False, ttest=False)\n",
    "        methods_dict[method_name] = temp\n",
    "    del df\n",
    "\n",
    "    if top_features_true != -1:\n",
    "        print(\"## Scoring results using known regulated features...\")\n",
    "        selected_regulated_features = topKfeatures\n",
    "        temp = np.sum(top_features_true)\n",
    "        if selected_regulated_features > temp:\n",
    "            selected_regulated_features = temp\n",
    "        print(\"\\t >> Number of up/down regulated features: {0}\".format(selected_regulated_features))\n",
    "        list_scores = list()\n",
    "        for method_idx, item in enumerate(methods_dict.items()):\n",
    "            if method_idx + 1 == len(methods):\n",
    "                print(\"\\t\\t--> Progress: {0:.4f}%; Method: {1:20}\".format(((method_idx + 1) / len(methods)) * 100,\n",
    "                                                                          methods[method_idx]))\n",
    "            else:\n",
    "                print(\"\\t\\t--> Progress: {0:.4f}%; Method: {1:20}\".format((method_idx / len(methods)) * 100,\n",
    "                                                                          methods[method_idx]), end=\"\\r\")\n",
    "            method_name, df = item\n",
    "            temp = [idx for idx, feature in enumerate(features_name)\n",
    "                    if feature in df['features'][:selected_regulated_features].tolist()]\n",
    "            top_features_pred = np.zeros((len(top_features_true)))\n",
    "            top_features_pred[temp] = 1\n",
    "            score = comparative_score(pred_features=top_features_pred, true_features=top_features_true,\n",
    "                                      metric=feature_metric)\n",
    "            list_scores.append(score)\n",
    "\n",
    "        df = pd.DataFrame(list_scores, columns=[\"Scores\"], index=methods)\n",
    "        df.to_csv(path_or_buf=os.path.join(RESULT_PATH, file_name + \"_features_scores.csv\"), sep=\",\")\n",
    "        print(\"## Plot barplot using the top {0} features...\".format(topKfeatures))\n",
    "        plot_barplot(X=list_scores, methods_name=methods, metric=\"f1\", suptitle=suptitle_name,\n",
    "                     file_name=file_name, save_path=RESULT_PATH)\n",
    "\n",
    "    temp = np.copy(y)\n",
    "    temp = temp.astype(str)\n",
    "    temp[np.where(y == 0)[0]] = control_name\n",
    "    temp[np.where(y == 1)[0]] = case_name\n",
    "    y = temp\n",
    "    list_scores = list()\n",
    "    score = 0\n",
    "    print(\"## Plot UMAP using all features ({0})...\".format(num_features))\n",
    "    score = plot_umap(X=X, y=y, subtypes=subtypes, features_name=features_name, num_features=num_features,\n",
    "                      standardize=True, num_neighbors=num_neighbors, min_dist=0, perform_cluster=True,\n",
    "                      cluster_type=cluster_type, num_clusters=num_clusters, max_clusters=max_clusters,\n",
    "                      apply_hungarian=False, heatmap_plot=False, num_jobs=num_jobs, suptitle=suptitle_name + \"\\nAll\",\n",
    "                      file_name=file_name + \"_all\", save_path=RESULT_PATH)\n",
    "    list_scores.append(score)\n",
    "    if top_features_true != -1:\n",
    "        print(\"## Plot UMAP using marker features ({0})...\".format(sum(top_features_true)))\n",
    "        temp = np.where(np.array(top_features_true) == 1)[0]\n",
    "        score = plot_umap(X=X[:, temp], y=y, subtypes=subtypes, features_name=features_name, num_features=temp.shape[0],\n",
    "                          standardize=True, num_neighbors=num_neighbors, min_dist=0, perform_cluster=True,\n",
    "                          cluster_type=cluster_type, num_clusters=num_clusters, max_clusters=max_clusters,\n",
    "                          apply_hungarian=False, heatmap_plot=False, num_jobs=num_jobs,\n",
    "                          suptitle=suptitle_name + \"\\nMarkers\",\n",
    "                          file_name=file_name + \"_markers\", save_path=RESULT_PATH)\n",
    "        list_scores.append(score)\n",
    "\n",
    "    if plot_topKfeatures:\n",
    "        print(\"## Plot UMAP using the top {0} features...\".format(topKfeatures))\n",
    "    else:\n",
    "        print(\"## Plot UMAP using the top features for each method...\")\n",
    "    for method_idx, item in enumerate(methods_dict.items()):\n",
    "        method_name, df = item\n",
    "        method_name = methods[method_idx]\n",
    "        save_name = methods_save_name[method_idx]\n",
    "        if total_progress == method_idx + 1:\n",
    "            print(\"\\t >> Progress: {0:.4f}%; Method: {1:20}\".format(((method_idx + 1) / total_progress) * 100,\n",
    "                                                                    method_name))\n",
    "        else:\n",
    "            print(\"\\t >> Progress: {0:.4f}%; Method: {1:20}\".format(((method_idx + 1) / total_progress) * 100,\n",
    "                                                                    method_name), end=\"\\r\")\n",
    "        if plot_topKfeatures:\n",
    "            temp = [idx for idx, feature in enumerate(features_name) if\n",
    "                    feature in df['features'].tolist()[:topKfeatures]]\n",
    "            temp_feature = [feature for idx, feature in enumerate(features_name) if\n",
    "                            feature in df['features'].tolist()[:topKfeatures]]\n",
    "        else:\n",
    "            temp = [idx for idx, feature in enumerate(features_name) if feature in df['features'].tolist()]\n",
    "            temp_feature = [feature for idx, feature in enumerate(features_name) if feature in df['features'].tolist()]\n",
    "        num_features = len(temp)\n",
    "        score = plot_umap(X=X[:, temp], y=y, subtypes=subtypes, features_name=temp_feature, num_features=num_features,\n",
    "                          standardize=True, num_neighbors=num_neighbors, min_dist=0.0, perform_cluster=True,\n",
    "                          cluster_type=cluster_type, num_clusters=num_clusters, max_clusters=max_clusters,\n",
    "                          apply_hungarian=False, heatmap_plot=False, num_jobs=num_jobs,\n",
    "                          suptitle=suptitle_name + \"\\n\" + method_name, file_name=file_name + \"_\" + save_name.lower(),\n",
    "                          save_path=RESULT_PATH)\n",
    "        df = pd.DataFrame(temp_feature, columns=[\"features\"])\n",
    "        df.to_csv(os.path.join(RESULT_PATH, file_name + \"_\" + save_name.lower() + \"_features.csv\"),\n",
    "                  sep=',', index=False, header=False)\n",
    "        if export_spring:\n",
    "            df = pd.DataFrame(X[:, temp])\n",
    "            df.to_csv(path_or_buf=os.path.join(RESULT_PATH, file_name + \"_\" + save_name.lower() + \"_expression.csv\"),\n",
    "                      sep=\",\", index=False, header=False)\n",
    "        del df\n",
    "        list_scores.append(score)\n",
    "    index = [\"All\"]\n",
    "    if top_features_true != -1:\n",
    "        index += [\"Markers\"]\n",
    "    df = pd.DataFrame(list_scores, columns=[\"Scores\"], index=index + methods)\n",
    "    df.to_csv(path_or_buf=os.path.join(RESULT_PATH, file_name + \"_cluster_quality.csv\"), sep=\",\")\n",
    "\n",
    "    print(\"## Plot barplot using to demonstrate clustering accuracy...\".format(topKfeatures))\n",
    "    plot_barplot(X=list_scores, methods_name=index + methods, metric=\"ari\",\n",
    "                 suptitle=suptitle_name, file_name=file_name, save_path=RESULT_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a GOEA object\n",
    "The GOEA object holds the Ontologies, Associations, and background.    \n",
    "Numerous studies can then be run withough needing to re-load the above items.    \n",
    "In this case, we only run one GOEA.    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run GOEA on Ionocytes using all Mouse Genes\n",
    "\n",
    "In this case study, we run GOEA for ~400 genes from PHet's results from ionocytes   \n",
    "and unknown populations of ionocytes. We do two tests to search for functions for   \n",
    "iocnocytes enriched terms and unknown populations enriched terms. In this example,  \n",
    "we choose to keep only the significant results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the permutation based significant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_features = os.path.join(os.getcwd(), \"permutaion_ionocytes_features.csv\")\n",
    "significant_features = pd.read_csv(significant_features, sep=',', header=None)[0].tolist()\n",
    "significant_features = [item.capitalize() for item in significant_features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load enriched terms for both ionocytes and unknown populations using SPRING results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = os.path.join(os.getcwd(), \"enriched_terms_ionocytes.txt\")\n",
    "features = pd.read_csv(features, sep='\\t', header=None)\n",
    "features.columns = [\"Features\", \"Scores\"]\n",
    "ionocytes_features = []\n",
    "uk_features = []\n",
    "for f in features.iterrows():\n",
    "    gene = f[1][0]\n",
    "    scores = f[1][1]\n",
    "    if gene.lower().startswith(\"rp\"):\n",
    "          continue\n",
    "    if scores > 0:\n",
    "         ionocytes_features.append(gene)\n",
    "    elif scores < 0:\n",
    "         uk_features.append(gene)\n",
    "uk_features = uk_features[::-1]\n",
    "\n",
    "ionocytes_features = ionocytes_features[:top_features]\n",
    "uk_features = uk_features[:top_features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, use features generated from Scanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ionocytes_features = os.path.join(os.getcwd(), \"pos_ionocytes_features.csv\")\n",
    "ionocytes_features = pd.read_csv(ionocytes_features, sep=',', header=None)[0].tolist()[:top_features]\n",
    "ionocytes_features = [item.capitalize() for item in ionocytes_features]\n",
    "\n",
    "uk_features = os.path.join(os.getcwd(), \"neg_ionocytes_features.csv\")\n",
    "uk_features = pd.read_csv(uk_features, sep=',', header=None)[0].tolist()[:top_features]\n",
    "uk_features = [item.capitalize() for item in uk_features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute GOEA on Ionocytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map symbols to ncbi id\n",
    "geneid2symbol = {}\n",
    "for gene in ionocytes_features:\n",
    "    temp = mouse_genes[mouse_genes[\"Symbol\"] == gene][\"GeneID\"]\n",
    "    if len(temp) != 0:\n",
    "        if len(temp) > 1:\n",
    "            geneid = int(temp.values.tolist()[0])\n",
    "        else:\n",
    "            geneid = int(temp)\n",
    "        geneid2symbol[geneid] = gene\n",
    "# 'p_' means \"pvalue\". 'fdr_bh' is the multipletest method we are currently using.\n",
    "geneids_study = geneid2symbol.keys()\n",
    "goea_results_all = goeaobj.run_study(geneids_study)\n",
    "goea_results_sig = [r for r in goea_results_all if r.p_fdr_bh < 0.05]\n",
    "# Save results to a TSV file\n",
    "goeaobj.wr_tsv(fout_tsv=\"phet_ionocytes_goea.tsv\", goea_results=goea_results_sig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute GOEA on Unknown Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map symbols to ncbi id\n",
    "geneid2symbol = {}\n",
    "for gene in uk_features:\n",
    "    temp = mouse_genes[mouse_genes[\"Symbol\"] == gene][\"GeneID\"]\n",
    "    if len(temp) != 0:\n",
    "        if len(temp) > 1:\n",
    "            geneid = int(temp.values.tolist()[0])\n",
    "        else:\n",
    "            geneid = int(temp)\n",
    "        geneid2symbol[geneid] = gene\n",
    "# 'p_' means \"pvalue\". 'fdr_bh' is the multipletest method we are currently using.\n",
    "geneids_study = geneid2symbol.keys()\n",
    "goea_results_all = goeaobj.run_study(geneids_study)\n",
    "goea_results_sig = [r for r in goea_results_all if r.p_fdr_bh < 0.05]\n",
    "# Save results to a TSV file\n",
    "goeaobj.wr_tsv(fout_tsv=\"phet_unknown_goea.tsv\", goea_results=goea_results_sig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute GOEA using Significant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map symbols to ncbi id\n",
    "geneid2symbol = {}\n",
    "for gene in significant_features:\n",
    "    temp = mouse_genes[mouse_genes[\"Symbol\"] == gene][\"GeneID\"]\n",
    "    if len(temp) != 0:\n",
    "        if len(temp) > 1:\n",
    "            geneid = int(temp.values.tolist()[0])\n",
    "        else:\n",
    "            geneid = int(temp)\n",
    "        geneid2symbol[geneid] = gene\n",
    "# 'p_' means \"pvalue\". 'fdr_bh' is the multipletest method we are currently using.\n",
    "geneids_study = geneid2symbol.keys()\n",
    "goea_results_all = goeaobj.run_study(geneids_study)\n",
    "goea_results_sig = [r for r in goea_results_all if r.p_fdr_bh < 0.05]\n",
    "# Save results to a TSV file\n",
    "goeaobj.wr_tsv(fout_tsv=\"phet_significant_goea.tsv\", goea_results=goea_results_sig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run GOEA on Selected Cell Types\n",
    "\n",
    "In this case study, we run GOEA using Markers from Basal, Ciliated, Club, and   \n",
    "Ionocytes to identify functions for unknown populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load markers\n",
    "pulseseq = os.path.join(os.getcwd(), \"pulseseq_all_features.csv\")\n",
    "pulseseq_features = pd.read_csv(pulseseq, sep=',').replace(np.nan, -1)\n",
    "cell_types = pulseseq_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_features = []\n",
    "for cell in cell_types:\n",
    "    cell_features = list(np.unique([item for item in pulseseq_features[cell] if item != -1]))\n",
    "    # Map symbols to ncbi id\n",
    "    geneid2symbol = {}\n",
    "    for gene in cell_features:\n",
    "        temp = mouse_genes[mouse_genes[\"Symbol\"] == gene][\"GeneID\"]\n",
    "        if len(temp) != 0:\n",
    "            if len(temp) > 1:\n",
    "                geneid = int(temp.values.tolist()[0])\n",
    "            else:\n",
    "                geneid = int(temp)\n",
    "            geneid2symbol[geneid] = gene\n",
    "    # 'p_' means \"pvalue\". 'fdr_bh' is the multipletest method we are currently using.\n",
    "    geneids_study = geneid2symbol.keys()\n",
    "    goea_results_all = goeaobj.run_study(geneids_study)\n",
    "    goea_results_sig = [r for r in goea_results_all if r.p_fdr_bh < 0.05]\n",
    "    # Save results to a TSV file\n",
    "    goeaobj.wr_tsv(fout_tsv=\"pulseseq_\"+ cell.lower() + \"_goea.tsv\", goea_results=goea_results_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative analysis among cell types\n",
    "scores = {}\n",
    "temp = os.path.join(os.getcwd(), \"phet_ionocytes_goea.tsv\")\n",
    "phet_ionocytes = pd.read_csv(temp, sep=\"\\t\")\n",
    "phet_ionocytes = phet_ionocytes[\"# GO\"].values.tolist()\n",
    "for cell in cell_types:\n",
    "    temp = os.path.join(os.getcwd(), \"pulseseq_\"+ cell.lower() + \"_goea.tsv\")\n",
    "    cell_go = pd.read_csv(temp, sep=\"\\t\")\n",
    "    cell_go = cell_go[\"# GO\"].values.tolist()\n",
    "    temp = []\n",
    "    for go in phet_ionocytes:\n",
    "        if go in cell_go:\n",
    "            temp.append(1)\n",
    "    scores[cell] = sum(temp)\n",
    "    # scores[cell] = sum(temp) / len(phet_ionocytes)\n",
    "print(\"Comparative analysis w.r.t. ionocytes:\")\n",
    "pd.DataFrame(scores.items(), columns=[\"Cells\", \"GO\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative analysis among cell types\n",
    "scores = {}\n",
    "temp = os.path.join(os.getcwd(), \"phet_unknown_goea.tsv\")\n",
    "phet_unknown = pd.read_csv(temp, sep=\"\\t\")\n",
    "phet_unknown = phet_unknown[\"# GO\"].values.tolist()\n",
    "for cell in cell_types:\n",
    "    temp = os.path.join(os.getcwd(), \"pulseseq_\"+ cell.lower() + \"_goea.tsv\")\n",
    "    cell_go = pd.read_csv(temp, sep=\"\\t\")\n",
    "    cell_go = cell_go[\"# GO\"].values.tolist()\n",
    "    temp = []\n",
    "    for go in phet_unknown:\n",
    "        if go in cell_go:\n",
    "            temp.append(1)\n",
    "    scores[cell] = sum(temp)\n",
    "    # scores[cell] = sum(temp) / len(phet_unknown)\n",
    "print(\"Comparative analysis w.r.t. unknown cells:\")\n",
    "pd.DataFrame(scores.items(), columns=[\"Cells\", \"GO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative analysis among cell types\n",
    "scores = {}\n",
    "temp = os.path.join(os.getcwd(), \"phet_significant_goea.tsv\")\n",
    "phet_unknown = pd.read_csv(temp, sep=\"\\t\")\n",
    "phet_unknown = phet_unknown[\"# GO\"].values.tolist()\n",
    "for cell in cell_types:\n",
    "    temp = os.path.join(os.getcwd(), \"pulseseq_\"+ cell.lower() + \"_goea.tsv\")\n",
    "    cell_go = pd.read_csv(temp, sep=\"\\t\")\n",
    "    cell_go = cell_go[\"# GO\"].values.tolist()\n",
    "    temp = []\n",
    "    for go in phet_unknown:\n",
    "        if go in cell_go:\n",
    "            temp.append(1)\n",
    "    scores[cell] = sum(temp)\n",
    "    # scores[cell] = sum(temp) / len(phet_unknown)\n",
    "print(\"Comparative analysis w.r.t. significant features for ionocytes:\")\n",
    "pd.DataFrame(scores.items(), columns=[\"Cells\", \"GO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative analysis among cell types\n",
    "scores = np.zeros((3, 3))\n",
    "temp = [\"ionocytes\", \"unknown\", \"significant\"]\n",
    "for i in range(3):\n",
    "    x = os.path.join(os.getcwd(), \"phet_\"+ temp[i] +\"_goea.tsv\")\n",
    "    x = pd.read_csv(x, sep=\"\\t\")\n",
    "    x = x[\"# GO\"].values.tolist()\n",
    "    for j in range(i+1, 3):\n",
    "        y = os.path.join(os.getcwd(), \"phet_\"+ temp[j] +\"_goea.tsv\")\n",
    "        y = pd.read_csv(y, sep=\"\\t\")\n",
    "        y = y[\"# GO\"].values.tolist()\n",
    "        for go in x:\n",
    "            if go in y:\n",
    "                scores[i,j] += 1\n",
    "pd.DataFrame(scores, columns=temp, index=temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot DAG of GO's \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [\"ionocytes\", \"unknown\", \"significant\"]\n",
    "for data_type in temp:\n",
    "    x = os.path.join(os.getcwd(), \"phet_\"+ data_type +\"_goea.tsv\")\n",
    "    x = pd.read_csv(x, sep=\"\\t\")\n",
    "    x = x[\"# GO\"].values.tolist()\n",
    "    goids = {t for t in x}\n",
    "    wang_r1 = SsWang(goids=goids, godag= godag, relationships=relationships)\n",
    "    r1_png = \"phet_\"+ data_type +\"_goea.png\"\n",
    "    r1_gosubdag = GoSubDag(goids, godag, relationships)\n",
    "    GoSubDagPlot(r1_gosubdag).plt_dag(r1_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"phet_ionocytes_goea.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"phet_unknown_goea.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
